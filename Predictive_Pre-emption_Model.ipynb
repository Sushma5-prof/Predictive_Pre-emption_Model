{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86601c0-abb2-4566-a56b-fda405b3c83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imported successfully!\n",
      "\n",
      "--- Initial Dataset Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1652 entries, 0 to 1651\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Event Description             1652 non-null   object\n",
      " 1   Year                          1652 non-null   int64 \n",
      " 2   Date Event Began              1652 non-null   object\n",
      " 3   Time Event Began              1643 non-null   object\n",
      " 4   Date of Restoration           1638 non-null   object\n",
      " 5   Time of Restoration           1632 non-null   object\n",
      " 6   Respondent                    1652 non-null   object\n",
      " 7   Geographic Areas              1651 non-null   object\n",
      " 8   NERC Region                   1650 non-null   object\n",
      " 9   Demand Loss (MW)              1246 non-null   object\n",
      " 10  Number of Customers Affected  1434 non-null   object\n",
      " 11  Tags                          1651 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 155.0+ KB\n",
      "None\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "                Event Description  Year Date Event Began Time Event Began  \\\n",
      "0  Severe Weather - Thunderstorms  2014        6/30/2014          8:00 PM   \n",
      "1  Severe Weather - Thunderstorms  2014        6/30/2014         11:20 PM   \n",
      "2  Severe Weather - Thunderstorms  2014        6/30/2014          5:55 PM   \n",
      "3    Fuel Supply Emergency - Coal  2014        6/27/2014          1:21 PM   \n",
      "4     Physical Attack - Vandalism  2014        6/24/2014          2:54 PM   \n",
      "\n",
      "  Date of Restoration Time of Restoration  \\\n",
      "0            7/2/2014             6:30 PM   \n",
      "1            7/1/2014             5:00 PM   \n",
      "2            7/1/2014             2:53 AM   \n",
      "3             Unknown             Unknown   \n",
      "4           6/24/2014             2:55 PM   \n",
      "\n",
      "                                Respondent       Geographic Areas NERC Region  \\\n",
      "0                 Exelon Corporation/ComEd               Illinois         RFC   \n",
      "1  Northern Indiana Public Service Company  North Central Indiana         RFC   \n",
      "2                              We Energies   Southeast  Wisconsin         MRO   \n",
      "3                              We Energies              Wisconsin         MRO   \n",
      "4               Tennessee Valley Authority   Nashville, Tennessee        SERC   \n",
      "\n",
      "  Demand Loss (MW) Number of Customers Affected                          Tags  \n",
      "0          Unknown                      420,000  severe weather, thunderstorm  \n",
      "1          Unknown                      127,000  severe weather, thunderstorm  \n",
      "2              424                      120,000  severe weather, thunderstorm  \n",
      "3          Unknown                      Unknown   fuel supply emergency, coal  \n",
      "4          Unknown                      Unknown           vandalism, physical  \n",
      "\n",
      "Standardized columns:\n",
      "Index(['event_description', 'year', 'date_event_began', 'time_event_began',\n",
      "       'date_of_restoration', 'time_of_restoration', 'respondent',\n",
      "       'geographic_areas', 'nerc_region', 'demand_loss_mw',\n",
      "       'number_of_customers_affected', 'tags'],\n",
      "      dtype='object')\n",
      "An unexpected error occurred during datetime conversion: Unknown datetime string format, unable to parse: 2/16/2006 Ongoing, at position 1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhma S\\AppData\\Local\\Temp\\ipykernel_5912\\2522043532.py:36: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['start_datetime'] = pd.to_datetime(df['date_event_began'] + ' ' + df['time_event_began'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'end_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'end_datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m\n\u001b[0;32m     51\u001b[0m     exit()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# --- 5. Calculate Outage Duration (Your Target Variable) ---\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Calculate the duration in minutes for convenience.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Filter out rows where end_datetime is before start_datetime, as this is a data error\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     59\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutage_duration_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtotal_seconds() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutage_duration_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column created.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'end_datetime'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Import the Dataset ---\n",
    "# Assuming your dataset is a CSV file named 'power_outage_data.csv'\n",
    "# Make sure this file is in the same directory as your script.\n",
    "\n",
    "file_path = 'Power_outage_dataset.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset imported successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please check the file path.\")\n",
    "    # Exit the script or handle the error gracefully\n",
    "    exit()\n",
    "\n",
    "# --- 2. Initial Data Inspection ---\n",
    "print(\"\\n--- Initial Dataset Info ---\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# --- 3. Clean and Standardize Column Names ---\n",
    "# This makes your code cleaner and avoids issues with spaces.\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "print(\"\\nStandardized columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# --- 4. Combine Date and Time Columns and Convert to Datetime ---\n",
    "# This is a critical step for a time-series analysis.\n",
    "# Assuming the columns from your image are named 'date_event_began' etc.\n",
    "\n",
    "try:\n",
    "    # Combine date and time columns into a single datetime object\n",
    "    df['start_datetime'] = pd.to_datetime(df['date_event_began'] + ' ' + df['time_event_began'])\n",
    "    df['end_datetime'] = pd.to_datetime(df['date_of_restoration'] + ' ' + df['time_of_restoration'])\n",
    "    \n",
    "    # Drop the old, now redundant columns\n",
    "    df = df.drop(columns=['date_event_began', 'time_event_began', 'date_of_restoration', 'time_of_restoration'])\n",
    "\n",
    "    print(\"\\nDates combined and converted to datetime objects.\")\n",
    "    print(df[['start_datetime', 'end_datetime']].head())\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error: One of the expected date/time columns was not found: {e}\")\n",
    "    print(\"Please check the column names in your CSV file and adjust the code.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during datetime conversion: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 5. Calculate Outage Duration (Your Target Variable) ---\n",
    "# Calculate the duration in minutes for convenience.\n",
    "\n",
    "# Filter out rows where end_datetime is before start_datetime, as this is a data error\n",
    "df = df[df['end_datetime'] > df['start_datetime']].copy()\n",
    "\n",
    "df['outage_duration_minutes'] = (df['end_datetime'] - df['start_datetime']).dt.total_seconds() / 60\n",
    "print(\"\\n'outage_duration_minutes' column created.\")\n",
    "print(df['outage_duration_minutes'].describe())\n",
    "\n",
    "# --- 6. Handle Missing Values (Example for customers_affected) ---\n",
    "# Let's say we have missing values in 'number_of_customers_affected'.\n",
    "# You can fill them with 0, as it's a reasonable assumption for a missing count.\n",
    "df['number_of_customers_affected'] = df['number_of_customers_affected'].fillna(0)\n",
    "print(\"\\nFilled missing values in 'number_of_customers_affected' with 0.\")\n",
    "\n",
    "# --- 7. Save the Cleaned Dataset ---\n",
    "# You might want to save the preprocessed data to a new file to avoid re-running the above code.\n",
    "df.to_csv('cleaned_power_outage_data.csv', index=False)\n",
    "print(\"\\nCleaned data saved to 'cleaned_power_outage_data.csv'.\")\n",
    "print(\"\\n--- Preprocessing Complete ---\")\n",
    "print(f\"Final dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e130a4-1001-44be-afa3-10c9540b6790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
